{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3886111,"sourceType":"datasetVersion","datasetId":2309134},{"sourceId":8102775,"sourceType":"datasetVersion","datasetId":4785321},{"sourceId":8102895,"sourceType":"datasetVersion","datasetId":4785405}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install librosa==0.8.1","metadata":{"execution":{"iopub.status.busy":"2024-04-12T01:18:19.243033Z","iopub.execute_input":"2024-04-12T01:18:19.243802Z","iopub.status.idle":"2024-04-12T01:18:23.856408Z","shell.execute_reply.started":"2024-04-12T01:18:19.243772Z","shell.execute_reply":"2024-04-12T01:18:23.855287Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting librosa==0.8.1\n  Downloading librosa-0.8.1-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.8.1) (3.0.1)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.8.1) (1.26.4)\nRequirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.8.1) (1.11.4)\nRequirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.8.1) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa==0.8.1) (1.3.2)\nRequirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.8.1) (5.1.1)\nCollecting resampy>=0.2.2 (from librosa==0.8.1)\n  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: numba>=0.43.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.8.1) (0.58.1)\nRequirement already satisfied: soundfile>=0.10.2 in /opt/conda/lib/python3.10/site-packages (from librosa==0.8.1) (0.12.1)\nRequirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.8.1) (1.8.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.8.1) (21.3)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.43.0->librosa==0.8.1) (0.41.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->librosa==0.8.1) (3.1.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.8.1) (4.2.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.8.1) (2.31.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.1) (3.2.0)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.10.2->librosa==0.8.1) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.8.1) (2.21)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (2024.2.2)\nDownloading librosa-0.8.1-py3-none-any.whl (203 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.8/203.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport librosa","metadata":{"execution":{"iopub.status.busy":"2024-04-12T18:53:22.802459Z","iopub.execute_input":"2024-04-12T18:53:22.803049Z","iopub.status.idle":"2024-04-12T18:53:26.326226Z","shell.execute_reply.started":"2024-04-12T18:53:22.803018Z","shell.execute_reply":"2024-04-12T18:53:26.325411Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Call model\nForked from https://github.com/RF5/simple-speaker-embedding","metadata":{}},{"cell_type":"code","source":"model = torch.hub.load('EmilYJuice/simple-speaker-embedding', 'convgru_embedder')\nmodel.eval()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-12T01:18:28.330421Z","iopub.execute_input":"2024-04-12T01:18:28.330783Z","iopub.status.idle":"2024-04-12T01:18:39.393553Z","shell.execute_reply.started":"2024-04-12T01:18:28.330757Z","shell.execute_reply":"2024-04-12T01:18:39.392597Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/hub.py:294: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n  warnings.warn(\nDownloading: \"https://github.com/EmilYJuice/simple-speaker-embedding/zipball/master\" to /root/.cache/torch/hub/master.zip\nDownloading: \"https://github.com/RF5/simple-speaker-embedding/releases/download/v1.0/convgru_ckpt_00700000_strip.pt\" to /root/.cache/torch/hub/checkpoints/convgru_ckpt_00700000_strip.pt\n100%|██████████| 121M/121M [00:00<00:00, 185MB/s]  \n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"ConvGRUEmbedder(\n  (model): ConvRNNEmbedder(\n    (conv_encoder): ConvEncoder(\n      (conv_layers): ModuleList(\n        (0): Sequential(\n          (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n          (1): Dropout(p=0.0, inplace=False)\n          (2): GroupNorm(512, 512, eps=1e-05, affine=True)\n          (3): GELU(approximate='none')\n        )\n        (1-4): 4 x Sequential(\n          (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n          (1): Dropout(p=0.0, inplace=False)\n          (2): GELU(approximate='none')\n        )\n        (5-6): 2 x Sequential(\n          (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n          (1): Dropout(p=0.0, inplace=False)\n          (2): GELU(approximate='none')\n        )\n      )\n    )\n    (rnn): GRU(512, 768, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n    (head): Linear(in_features=1536, out_features=256, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"import shutil\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-04-12T19:07:21.407028Z","iopub.execute_input":"2024-04-12T19:07:21.407392Z","iopub.status.idle":"2024-04-12T19:07:21.411617Z","shell.execute_reply.started":"2024-04-12T19:07:21.407363Z","shell.execute_reply":"2024-04-12T19:07:21.410725Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Prepare dataset (first 40 speakers from VCTK)","metadata":{}},{"cell_type":"code","source":"# extract p225,p226,p227,p228\nsource_folder = '/kaggle/input/vctk48'\noutput_folder = '/kaggle/working/new_wavs'\n\nif not os.path.exists(output_folder):\n    os.makedirs(output_folder)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T01:18:54.961059Z","iopub.execute_input":"2024-04-12T01:18:54.961395Z","iopub.status.idle":"2024-04-12T01:18:54.966554Z","shell.execute_reply.started":"2024-04-12T01:18:54.961372Z","shell.execute_reply":"2024-04-12T01:18:54.965607Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"all_folders = [os.path.join(source_folder, f) for f in os.listdir(source_folder) if os.path.isdir(os.path.join(source_folder, f))]","metadata":{"execution":{"iopub.status.busy":"2024-04-12T01:18:56.953699Z","iopub.execute_input":"2024-04-12T01:18:56.954307Z","iopub.status.idle":"2024-04-12T01:18:56.974166Z","shell.execute_reply.started":"2024-04-12T01:18:56.954279Z","shell.execute_reply":"2024-04-12T01:18:56.973478Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"all_folders.sort()\nselected_folders = all_folders[:40]","metadata":{"execution":{"iopub.status.busy":"2024-04-12T01:19:13.664249Z","iopub.execute_input":"2024-04-12T01:19:13.664861Z","iopub.status.idle":"2024-04-12T01:19:13.668869Z","shell.execute_reply.started":"2024-04-12T01:19:13.664831Z","shell.execute_reply":"2024-04-12T01:19:13.667940Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for folder in selected_folders:\n    # Define the destination path for the folder\n    dest_path = os.path.join(output_folder, os.path.basename(folder))\n    \n    # Copy the folder to the destination\n    shutil.copytree(folder, dest_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T01:19:27.081627Z","iopub.execute_input":"2024-04-12T01:19:27.082400Z","iopub.status.idle":"2024-04-12T01:20:55.534801Z","shell.execute_reply.started":"2024-04-12T01:19:27.082370Z","shell.execute_reply":"2024-04-12T01:20:55.533998Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Downsampling all wav file to 16k Hz","metadata":{}},{"cell_type":"code","source":"import soundfile as sf","metadata":{"execution":{"iopub.status.busy":"2024-04-12T01:21:20.299653Z","iopub.execute_input":"2024-04-12T01:21:20.299988Z","iopub.status.idle":"2024-04-12T01:21:20.304422Z","shell.execute_reply.started":"2024-04-12T01:21:20.299963Z","shell.execute_reply":"2024-04-12T01:21:20.303387Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# downsampling for all wav files\nrootDir = '/kaggle/working/new_wavs'\n\ndirName, subdirList, _ = next(os.walk(rootDir))\n\nfor subdir in sorted(subdirList):\n    _,_, fileList = next(os.walk(os.path.join(dirName,subdir)))\n    for fileName in sorted(fileList):\n        filepath = os.path.join(rootDir, subdir, fileName)\n        audio, sample_rate = librosa.load(filepath, sr=16000)\n        output_file_path = filepath  \n        sf.write(output_file_path, audio, sample_rate)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T01:21:23.513266Z","iopub.execute_input":"2024-04-12T01:21:23.513885Z","iopub.status.idle":"2024-04-12T01:23:21.365867Z","shell.execute_reply.started":"2024-04-12T01:21:23.513857Z","shell.execute_reply":"2024-04-12T01:23:21.364997Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## generate train.pkl (speaker embedding \"convgru\")","metadata":{}},{"cell_type":"code","source":"# Directory containing mel-spectrograms\nrootDir = '/kaggle/input/679-40-wavs/new_spmel'\ndirName, subdirList, _ = next(os.walk(rootDir))\nprint('Found directory: %s' % dirName)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T19:14:27.051047Z","iopub.execute_input":"2024-04-12T19:14:27.052089Z","iopub.status.idle":"2024-04-12T19:14:27.058630Z","shell.execute_reply.started":"2024-04-12T19:14:27.052055Z","shell.execute_reply":"2024-04-12T19:14:27.057753Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Found directory: /kaggle/input/679-40-wavs/new_spmel\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle","metadata":{"execution":{"iopub.status.busy":"2024-04-12T19:14:52.611422Z","iopub.execute_input":"2024-04-12T19:14:52.611808Z","iopub.status.idle":"2024-04-12T19:14:52.616110Z","shell.execute_reply.started":"2024-04-12T19:14:52.611775Z","shell.execute_reply":"2024-04-12T19:14:52.615088Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"speakers = []\nfor speaker in sorted(subdirList):\n    print('Processing speaker: %s' % speaker)\n    utterances = []\n    utterances.append(speaker)\n    _, _, fileList = next(os.walk(os.path.join(dirName,speaker)))\n    \n    # make speaker embedding\n    assert len(fileList) >= num_uttrs\n    idx_uttrs = np.random.choice(len(fileList), size=num_uttrs, replace=False)\n    embs = []\n    for i in range(num_uttrs):\n        tmp = np.load(os.path.join(dirName, speaker, fileList[idx_uttrs[i]]))\n        candidates = np.delete(np.arange(len(fileList)), idx_uttrs)\n        # choose another utterance if the current one is too short\n        while tmp.shape[0] < len_crop:\n            idx_alt = np.random.choice(candidates)\n            tmp = np.load(os.path.join(dirName, speaker, fileList[idx_alt]))\n            candidates = np.delete(candidates, np.argwhere(candidates==idx_alt))\n        left = np.random.randint(0, tmp.shape[0]-len_crop)\n        melsp = torch.from_numpy(tmp[np.newaxis, left:left+len_crop, :]).cuda()\n        emb = C(melsp)\n        embs.append(emb.detach().squeeze().cpu().numpy())     \n    utterances.append(np.mean(embs, axis=0))\n    \n    # create file list\n    for fileName in sorted(fileList):\n        utterances.append(os.path.join(speaker,fileName))\n    speakers.append(utterances)\n    \nwith open(os.path.join('/kaggle/working/', 'train_40_wavs.pkl'), 'wb') as handle:\n    pickle.dump(speakers, handle)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T19:15:30.861972Z","iopub.execute_input":"2024-04-12T19:15:30.862652Z","iopub.status.idle":"2024-04-12T19:15:32.808048Z","shell.execute_reply.started":"2024-04-12T19:15:30.862613Z","shell.execute_reply":"2024-04-12T19:15:32.807001Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Processing speaker: p225\nProcessing speaker: p228\nProcessing speaker: p233\nProcessing speaker: p256\nProcessing speaker: p257\nProcessing speaker: p258\nProcessing speaker: p266\n","output_type":"stream"}]},{"cell_type":"code","source":"# generate speaker embedding\nspeakers = []\n# Assuming subdirList is a list of speaker directory names under dirName\nfor speaker in sorted(subdirList):\n    print('Processing speaker: %s' % speaker)\n    utterances = [speaker]  # Start with speaker name\n    \n    speaker_dir = os.path.join(dirName, speaker)\n    _, _, fileList = next(os.walk(speaker_dir))\n    \n    embs = []\n    for i in fileList:\n#         mel = model.melspec_from_file(os.path.join(speaker_dir, i))\n#         embedding = model(mel[None])\n        wav, _ = librosa.load(os.path.join(speaker_dir, i), sr=16000)\n        wav = torch.from_numpy(wav).float()\n        embedding = model(wav[None])\n        embs.append(embedding.detach().squeeze().cpu().numpy())     \n    utterances.append(np.mean(embs, axis=0))\n    \n    # create file list\n    for fileName in sorted(fileList):\n        utterances.append(os.path.join(speaker,fileName))\n    speakers.append(utterances)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T19:08:44.281579Z","iopub.execute_input":"2024-04-12T19:08:44.282254Z","iopub.status.idle":"2024-04-12T19:08:49.628755Z","shell.execute_reply.started":"2024-04-12T19:08:44.282220Z","shell.execute_reply":"2024-04-12T19:08:49.627311Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Processing speaker: p225\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/1321384876.py:15: UserWarning: PySoundFile failed. Trying audioread instead.\n  wav, _ = librosa.load(os.path.join(speaker_dir, i), sr=16000)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n","\u001b[0;31mLibsndfileError\u001b[0m: Error opening '/kaggle/input/679-40-wavs/new_spmel/p225/p225_241.npy': Format not recognised.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNoBackendError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     embs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m fileList:\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#         mel = model.melspec_from_file(os.path.join(speaker_dir, i))\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#         embedding = model(mel[None])\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m         wav, _ \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeaker_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m         wav \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(wav)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     17\u001b[0m         embedding \u001b[38;5;241m=\u001b[39m model(wav[\u001b[38;5;28;01mNone\u001b[39;00m])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[1;32m    180\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    182\u001b[0m     )\n\u001b[0;32m--> 183\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/librosa/util/decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[1;32m     58\u001b[0m )\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:239\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    236\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43maudioread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[1;32m    242\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/audioread/__init__.py:132\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# All backends failed!\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m NoBackendError()\n","\u001b[0;31mNoBackendError\u001b[0m: "],"ename":"NoBackendError","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"with open(os.path.join(\"/kaggle/working/\", 'train_new_40.pkl'), 'wb') as handle:\n    pickle.dump(speakers, handle)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T01:33:12.044888Z","iopub.execute_input":"2024-04-12T01:33:12.045524Z","iopub.status.idle":"2024-04-12T01:33:12.054555Z","shell.execute_reply.started":"2024-04-12T01:33:12.045492Z","shell.execute_reply":"2024-04-12T01:33:12.053693Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## get_spectorm","metadata":{}},{"cell_type":"code","source":"import os\nimport pickle\nimport numpy as np\nimport soundfile as sf\nfrom scipy import signal\nfrom scipy.signal import get_window\nfrom librosa.filters import mel\nfrom numpy.random import RandomState","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def butter_highpass(cutoff, fs, order=5):\n    nyq = 0.5 * fs\n    normal_cutoff = cutoff / nyq\n    b, a = signal.butter(order, normal_cutoff, btype='high', analog=False)\n    return b, a\n    \n    \ndef pySTFT(x, fft_length=1024, hop_length=256):\n    \n    x = np.pad(x, int(fft_length//2), mode='reflect')\n    \n    noverlap = fft_length - hop_length\n    shape = x.shape[:-1]+((x.shape[-1]-noverlap)//hop_length, fft_length)\n    strides = x.strides[:-1]+(hop_length*x.strides[-1], x.strides[-1])\n    result = np.lib.stride_tricks.as_strided(x, shape=shape,\n                                             strides=strides)\n    \n    fft_window = get_window('hann', fft_length, fftbins=True)\n    result = np.fft.rfft(fft_window * result, n=fft_length).T\n    \n    return np.abs(result)    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mel_basis = mel(sr=16000, n_fft=1024, fmin=90, fmax=7600, n_mels=80).T\nmin_level = np.exp(-100 / 20 * np.log(10))\nb, a = butter_highpass(30, 16000, order=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# audio file directory\nrootDir = '/kaggle/working/new_wavs'\n# spectrogram directory\ntargetDir = '/kaggle/working/new_spmel'\n\n\ndirName, subdirList, _ = next(os.walk(rootDir))\nprint('Found directory: %s' % dirName)\n\nfor subdir in sorted(subdirList):\n    print(subdir)\n    if not os.path.exists(os.path.join(targetDir, subdir)):\n        os.makedirs(os.path.join(targetDir, subdir))\n    _,_, fileList = next(os.walk(os.path.join(dirName,subdir)))\n    prng = RandomState(int(subdir[1:])) \n    for fileName in sorted(fileList):\n        # Read audio file\n        x, fs = sf.read(os.path.join(dirName,subdir,fileName))\n        # Remove drifting noise\n        y = signal.filtfilt(b, a, x)\n        # Ddd a little random noise for model roubstness\n        wav = y * 0.96 + (prng.rand(y.shape[0])-0.5)*1e-06\n        # Compute spect\n        D = pySTFT(wav).T\n        # Convert to mel and normalize\n        D_mel = np.dot(D, mel_basis)\n        D_db = 20 * np.log10(np.maximum(min_level, D_mel)) - 16\n        S = np.clip((D_db + 100) / 100, 0, 1)    \n        # save spect    \n        np.save(os.path.join(targetDir, subdir, fileName[:-4]),\n                S.astype(np.float32), allow_pickle=False)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r file.zip /kaggle/working","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'file.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}